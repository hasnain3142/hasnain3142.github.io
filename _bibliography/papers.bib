---
---
@string{arxiv = {arxiv,}}

@article{10.48550/arXiv.2503.09837,
  title={On the Limitations of Vision Language Models in Understanding Image Transforms},
  author={Ahmad Mustafa Anis and \textbf{Hasnain Ali} and Saquib Sarfraz},
  abstract={Vision Language Models (VLMs) have demonstrated significant potential in various downstream tasks, including Image/Video Generation, Visual Question Answering, Multimodal Chatbots, and Video Understanding. However, these
models often struggle with basic image transformations.
This paper investigates the image-level understanding of
VLMs, specifically CLIP by OpenAI and SigLIP by Google.
Our findings reveal that these models lack comprehension
of multiple image-level augmentations. To facilitate this
study, we created an augmented version of the Flickr8k
dataset, pairing each image with a detailed description of
the applied transformation. We further explore how this deficiency impacts downstream tasks, particularly in image
editing, and evaluate the performance of state-of-the-art
Image2Image models on simple transformations},
  year={2025},
  month={June},
  publisher=arxiv,
  venue=CVPR 2025w: Computer Vision in the Wild 
  doi={10.48550/arXiv.2503.09837},
  url={https://arxiv.org/abs/2503.09837},
  html={https://arxiv.org/pdf/2503.09837},
  pdf={2509.06274v1.pdf},
  preview={vlm_llm.jpg},
  selected={true}
}